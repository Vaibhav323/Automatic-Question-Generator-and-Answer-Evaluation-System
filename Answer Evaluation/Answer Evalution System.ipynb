{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-19T17:53:28.775414Z",
     "start_time": "2024-04-19T17:53:28.039108Z"
    }
   },
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vmlon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vmlon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T17:16:37.834866Z",
     "start_time": "2024-04-23T17:16:32.046126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QMainWindow, QFileDialog, QMessageBox, QPushButton, QVBoxLayout, QWidget\n",
    "from PyQt5.QtGui import QFont, QIcon\n",
    "from PyQt5.QtCore import QDir, Qt\n",
    "\n",
    "# Define a global variable to store the CSV file path\n",
    "csv_file_path = None\n",
    "\n",
    "class MainWindow(QMainWindow):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.initUI()\n",
    "\n",
    "    def initUI(self):\n",
    "        self.setWindowTitle(\"CSV File Upload\")\n",
    "        self.setWindowIcon(QIcon('icon.png'))  # Replace 'icon.png' with your icon file\n",
    "        self.setGeometry(100, 100, 400, 200)\n",
    "        self.setStyleSheet(\"\"\"\n",
    "            QMainWindow {\n",
    "                background-color: #F0F0F0;\n",
    "            }\n",
    "            QPushButton {\n",
    "                background-color: #4CAF50;\n",
    "                color: white;\n",
    "                padding: 10px 20px;\n",
    "                border-radius: 5px;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            QPushButton:hover {\n",
    "                background-color: #45a049;\n",
    "            }\n",
    "        \"\"\")\n",
    "\n",
    "        central_widget = QWidget()\n",
    "        layout = QVBoxLayout()\n",
    "\n",
    "        open_button = QPushButton(\"Open CSV\")\n",
    "        open_button.setFont(QFont(\"Arial\", 12))\n",
    "        open_button.clicked.connect(self.openFile)\n",
    "\n",
    "        layout.addStretch()\n",
    "        layout.addWidget(open_button, alignment=Qt.AlignCenter)\n",
    "        layout.addStretch()\n",
    "\n",
    "        central_widget.setLayout(layout)\n",
    "        self.setCentralWidget(central_widget)\n",
    "\n",
    "    def openFile(self):\n",
    "        global csv_file_path\n",
    "        file_path, _ = QFileDialog.getOpenFileName(self, \"Open CSV\", QDir.homePath(), \"CSV Files (*.csv)\")\n",
    "        if file_path:\n",
    "            try:\n",
    "                csv_file_path = file_path  # Store the CSV file path in the global variable\n",
    "                QMessageBox.information(self, \"Success\", \"CSV file selected successfully.\")\n",
    "                self.close()  # Close the \"Open CSV\" window\n",
    "\n",
    "                # You can access the CSV file path using the csv_file_path variable\n",
    "                # and read the file data using pandas or any other library\n",
    "\n",
    "            except Exception as e:\n",
    "                QMessageBox.warning(self, \"Error\", str(e))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app = QApplication(sys.argv)\n",
    "    window = MainWindow()\n",
    "    window.show()\n",
    "    sys.exit(app.exec_())"
   ],
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[1;31mSystemExit\u001B[0m\u001B[1;31m:\u001B[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vmlon\\anaconda3\\envs\\Project_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3465: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-23T17:16:39.420251Z"
    }
   },
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from flask import Flask ,redirect ,url_for ,request , render_template ,flash\n",
    "\n",
    "import sqlite3\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# csv_filename = 'Qcsv.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "df['QuestionID'] = df.index + 1\n",
    "print(df)\n",
    "\n",
    "def GrammerChecker(answer):\n",
    "    req = requests.get(\"https://api.textgears.com/check.php?text=\" + answer + \"&key=JmcxHCCPZ7jfXLF6\")\n",
    "    no_of_errors = len(req.json()['errors'])\n",
    "\n",
    "\n",
    "\n",
    "    if no_of_errors > 5 :\n",
    "        g = 0\n",
    "    else:\n",
    "        g = 1\n",
    "    return g\n",
    "\n",
    "\n",
    "def KeyWordmatching(X, Y_lst):\n",
    "    result = 0\n",
    "    X_list = word_tokenize(X)\n",
    "\n",
    "    sw = stopwords.words('english')\n",
    "    l1 = []; l2 = []\n",
    "\n",
    "    X_set = {w for w in X_list if not w in sw}\n",
    "\n",
    "    for Y in Y_lst:\n",
    "        Y_list = word_tokenize(Y)\n",
    "        Y_set = {w for w in Y_list if not w in sw}\n",
    "        # form a set containing keywords of both strings\n",
    "        rvector = X_set.union(Y_set)\n",
    "        if not rvector:\n",
    "            return 6  # Return worst score if no common keywords\n",
    "        for w in rvector:\n",
    "            if w in X_set:\n",
    "                l1.append(1)  # create a vector\n",
    "            else:\n",
    "                l1.append(0)\n",
    "            if w in Y_set:\n",
    "                l2.append(1)\n",
    "            else:\n",
    "                l2.append(0)\n",
    "        c = 0\n",
    "\n",
    "        dot_product = np.dot(l1, l2)\n",
    "        magnitude_l1 = np.linalg.norm(l1)\n",
    "        magnitude_l2 = np.linalg.norm(l2)\n",
    "        cosine = dot_product / (magnitude_l1 * magnitude_l2)\n",
    "\n",
    "        result += cosine\n",
    "\n",
    "    cosine = result / 3\n",
    "    kval = 0\n",
    "    if cosine > 90:\n",
    "        kval = 1\n",
    "    elif cosine > 80:\n",
    "        kval = 2\n",
    "    elif cosine > 60:\n",
    "        kval = 3\n",
    "    elif cosine > 40:\n",
    "        kval = 4\n",
    "    elif cosine > 20:\n",
    "        kval = 5\n",
    "    else:\n",
    "        kval = 6\n",
    "    return kval\n",
    "\n",
    "\n",
    "\n",
    "def CheckLenght(client_answer):\n",
    "\n",
    "    client_ans = len(client_answer.split())\n",
    "\n",
    "    kval1 = 0\n",
    "    if client_ans > 50:\n",
    "        kval1 = 1\n",
    "    elif client_ans > 40:\n",
    "        kval1 = 2\n",
    "    elif client_ans > 30:\n",
    "        kval1 = 3\n",
    "    elif client_ans > 20:\n",
    "        kval1 = 4\n",
    "    elif client_ans > 10:\n",
    "        kval1 = 5\n",
    "    else:\n",
    "        kval1 = 6\n",
    "    return kval1\n",
    "\n",
    "\n",
    "class DocSim:\n",
    "    def __init__(self, w2v_model, stopwords=None):\n",
    "        self.w2v_model = w2v_model\n",
    "        self.stopwords = stopwords if stopwords is not None else []\n",
    "\n",
    "    def vectorize(self, doc: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Identify the vector values for each word in the given document\n",
    "        :param doc:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        doc = doc.lower()\n",
    "        words = [w for w in doc.split(\" \") if w not in self.stopwords]\n",
    "        word_vecs = []\n",
    "        for word in words:\n",
    "            try:\n",
    "                vec = self.w2v_model[word]\n",
    "                word_vecs.append(vec)\n",
    "            except KeyError:\n",
    "\n",
    "                pass\n",
    "\n",
    "        vector = np.mean(word_vecs, axis=0)\n",
    "        return vector\n",
    "\n",
    "    def _cosine_sim(self, vecA, vecB):\n",
    "        \"\"\"Find the cosine similarity distance between two vectors.\"\"\"\n",
    "        csim = np.dot(vecA, vecB) / (np.linalg.norm(vecA) * np.linalg.norm(vecB))\n",
    "        if np.isnan(np.sum(csim)):\n",
    "            return 0\n",
    "        return csim\n",
    "\n",
    "\n",
    "    def calculate_similarity(self, source_doc, target_docs=None, threshold=0):\n",
    "        \"\"\"Calculates & returns similarity scores between given source document & all\n",
    "        the target documents.\"\"\"\n",
    "        if not target_docs:\n",
    "            return []\n",
    "\n",
    "        if isinstance(target_docs, str):\n",
    "            target_docs = [target_docs]\n",
    "\n",
    "        source_vec = self.vectorize(source_doc)\n",
    "        results = []\n",
    "        result=[]\n",
    "        for doc in target_docs:\n",
    "            target_vec = self.vectorize(doc)\n",
    "            sim_score = self._cosine_sim(source_vec, target_vec)\n",
    "            result.append(sim_score)\n",
    "            if sim_score > threshold:\n",
    "                results.append({\"score\": sim_score, \"doc\": doc})\n",
    "            results.sort(key=lambda k: k[\"score\"], reverse=True)\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "email = \"null\"\n",
    "name=\"null\"\n",
    "roll=\"null\"\n",
    "\n",
    "\n",
    "questions = df.to_dict(orient='records')\n",
    "\n",
    "@app.route('/')\n",
    "def Base_qstn_paper_set():\n",
    "    return render_template('index.html',questions=questions)\n",
    "\n",
    "\n",
    "\n",
    "@app.route('/foo', methods=['POST', 'GET'])\n",
    "def foo():\n",
    "    if request.method == 'POST':\n",
    "        question_index = int(request.form['question_index'])\n",
    "        first = request.form['answer{}'.format(question_index)]\n",
    "        second = request.form['answer{}'.format(question_index + 1)]\n",
    "\n",
    "        name = request.form['name']\n",
    "        roll = request.form['roll']\n",
    "        email = request.form['emailID']\n",
    "        print(name)\n",
    "        print(first)\n",
    "\n",
    "        googlenews_model_path = './GoogleNews-vectors-negative300.bin'\n",
    "        stopwords_path = \"./stopword.txt\"\n",
    "\n",
    "\n",
    "        model = KeyedVectors.load_word2vec_format(googlenews_model_path, binary=True)\n",
    "        with open(stopwords_path, 'r') as fh:\n",
    "            stopwords = fh.read().split(\",\")\n",
    "        ds = DocSim(model,stopwords)\n",
    "        print(\"hello\")\n",
    "\n",
    "        def short(source_doc1,target_answer):\n",
    "            target_docs = [target_answer]\n",
    "            sim_scores = ds.calculate_similarity(source_doc1, target_docs)\n",
    "            key_match=KeyWordmatching(source_doc1,target_docs)\n",
    "            key_Error=GrammerChecker(source_doc1)\n",
    "\n",
    "            marks1 = max(0, min(50, ((sum(sim_scores) / len(sim_scores)) * 40) + (5/key_match) + (5 * key_Error)))\n",
    "            return marks1\n",
    "\n",
    "\n",
    "        def essay(source_doc2,target_answer):\n",
    "            target_docs = [target_answer]\n",
    "            sim_scores = ds.calculate_similarity(source_doc2, target_docs)\n",
    "            key_match=KeyWordmatching(source_doc2,target_docs)\n",
    "            key_Error=GrammerChecker(source_doc2)\n",
    "            key_length=CheckLenght(source_doc2)\n",
    "            marks2 = max(0, min(50, ((sum(sim_scores) / len(sim_scores)) * 30) + (5/key_match) + (5 * key_Error) + (10/key_length)))\n",
    "            return marks2\n",
    "\n",
    "        question_row = df.iloc[question_index - 1]\n",
    "        mark1= short(first,question_row['Answer'])\n",
    "        mark2= essay(second,question_row['Answer'])\n",
    "        # mark1=mark1/2\n",
    "        mark1=round(mark1)\n",
    "        mark2=round(mark2)\n",
    "        # mark2=mark2/2\n",
    "        print(mark1)\n",
    "        with sqlite3.connect(\"employee.db\") as con:\n",
    "            cur = con.cursor()\n",
    "            cur.execute(\"INSERT into Employees (name, roll, email, marks_short, marks_des ) values (?,?,?,?,?)\",(name,roll,email,mark1,mark2))\n",
    "            con.commit()\n",
    "\n",
    "            print(\"After Insert in DB\")\n",
    "            msg = \"Employee successfully Added\"\n",
    "    return redirect(url_for('Recorded'))\n",
    "\n",
    "@app.route('/Recorded')\n",
    "def Recorded():\n",
    "    return render_template('base.html')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from werkzeug.serving import run_simple\n",
    "    run_simple('localhost', 8000, app)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://localhost:8000/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Question  \\\n",
      "0                    Define ASPECT OF FUNCTIONALITY.   \n",
      "1                     Explain in detail INHERITANCE.   \n",
      "2                        What do you mean by METHOD.   \n",
      "3  Write a short note on BEHAVIOR FROM ANOTHER CL...   \n",
      "4           Write a short note on MANAGE COMPLEXITY.   \n",
      "\n",
      "                                              Answer  QuestionID  \n",
      "0  Modularity: Modularity is the principle of div...           1  \n",
      "1  Inheritance also supports the concept of polym...           2  \n",
      "2  Method overriding allows subclasses to provide...           3  \n",
      "3  Inheritance: Inheritance is a mechanism that a...           4  \n",
      "4  By encapsulating related data and behavior wit...           5  \n",
      "ABC\n",
      "Modularity: Modularity is the principle of dividing a program into smaller, self-contained modules or classes, each responsible for a specific aspect of functionality\n",
      "hello\n",
      "45.0\n",
      "After Insert in DB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [23/Apr/2024 22:47:38] \"POST /foo HTTP/1.1\" 302 -\n",
      "127.0.0.1 - - [23/Apr/2024 22:47:38] \"GET /Recorded HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
